{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\shend\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.40.0)\n",
      "Requirement already satisfied: torch in c:\\users\\shend\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.13.0)\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py egg_info did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [15 lines of output]\n",
      "      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "      rather than 'sklearn' for pip commands.\n",
      "      \n",
      "      Here is how to fix this error in the main use cases:\n",
      "      - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "      - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "      - if the 'sklearn' package is used by one of your dependencies,\n",
      "        it would be great if you take some time to track which package uses\n",
      "        'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "      - as a last resort, set the environment variable\n",
      "        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "      \n",
      "      More information is available at\n",
      "      https://github.com/scikit-learn/sklearn-pypi-package\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n",
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfplumber in c:\\users\\shend\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: pdfminer.six==20231228 in c:\\users\\shend\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pdfplumber) (20231228)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\shend\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pdfplumber) (4.29.0)\n",
      "Requirement already satisfied: Pillow>=9.1 in c:\\users\\shend\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pdfplumber) (9.2.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\shend\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pdfminer.six==20231228->pdfplumber) (2.1.1)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\shend\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pdfminer.six==20231228->pdfplumber) (42.0.5)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\shend\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.15.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\shend\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers torch sklearn pandas\n",
    "! pip install pdfplumber  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import os\n",
    "\n",
    "def pdf_to_text(pdf_path):\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "def load_dataset(root_dir):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    label_map = {}\n",
    "    for label_dir in os.listdir(root_dir):\n",
    "        class_path = os.path.join(root_dir, label_dir)\n",
    "        if os.path.isdir(class_path):\n",
    "            label_index = len(label_map)\n",
    "            label_map[label_dir] = label_index\n",
    "            for filename in os.listdir(class_path):\n",
    "                if filename.lower().endswith('.pdf'):\n",
    "                    file_path = os.path.join(class_path, filename)\n",
    "                    text = pdf_to_text(file_path)\n",
    "                    if text:  \n",
    "                        texts.append(text)\n",
    "                        labels.append(label_index)\n",
    "    return texts, labels, label_map\n",
    "\n",
    "texts, labels, label_map = load_dataset('./data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shend\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def encode_texts(texts):\n",
    "    return tokenizer(texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "train_encodings = encode_texts(train_texts)\n",
    "test_encodings = encode_texts(test_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "class ResumeDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = ResumeDataset(train_encodings, train_labels)\n",
    "test_dataset = ResumeDataset(test_encodings, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\shend\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\shend\\AppData\\Local\\Temp\\ipykernel_49664\\1512967528.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.0453323869101974\n",
      "Epoch 2, Loss: 0.8170448834278498\n",
      "Epoch 3, Loss: 0.5861756590355831\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_map))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "def train(model, data_loader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in data_loader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "for epoch in range(3):\n",
    "    loss = train(model, train_loader)\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shend\\AppData\\Local\\Temp\\ipykernel_49664\\1512967528.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7907444668008048\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate(model, data_loader):\n",
    "    model.eval()\n",
    "    predictions, true_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            logits = outputs.logits\n",
    "            predictions.extend(torch.argmax(logits, dim=-1).tolist())\n",
    "            true_labels.extend(batch['labels'].tolist())\n",
    "    return accuracy_score(true_labels, predictions)\n",
    "\n",
    "accuracy = evaluate(model, test_loader)\n",
    "print(f'Test Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Profession: BANKING\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "def pdf_to_text(pdf_path):\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text() if page.extract_text() else \"\"\n",
    "    return text\n",
    "\n",
    "def prepare_input(text):\n",
    "    encoded_input = tokenizer(text, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    return encoded_input\n",
    "\n",
    "def predict(model, encoded_input):\n",
    "    model.eval() \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoded_input.to(device))\n",
    "        pred = torch.argmax(outputs.logits, dim=1).item()\n",
    "    return pred\n",
    "\n",
    "text = \"\"\"\n",
    "We are looking for an Entry Level Tax Accountant to join our team in Metro Atlanta! We are looking for someone who is self-motivated and able to work in a fast-paced environment. All qualified individuals are encouraged to apply\n",
    "\n",
    "RESPONSIBILITIES -\n",
    "• Prepare Business, Real Estate Partnership\n",
    "• Prepare multi-State Income Tax Preparation\n",
    "• Prepare sales tax return preparation\n",
    "• Conduct tax research and form meaningful conclusions for specific projects\n",
    "• Respond to tax notices\n",
    "\n",
    "SKILLS -\n",
    "• Bachelor's Degree Required, in Accounting/Finance or related degree\n",
    "• 6 Months + of related experience (internships will be considered)\n",
    "• Strong interpersonal skills. Candidate must have the ability to work in teams and help promote a team environment as well as professionally manage client relationships\n",
    "• Ability to use Microsoft Offices, Outlook, and various accounting applications\n",
    "\"\"\"\n",
    "encoded_input = prepare_input(text)\n",
    "profession_index = predict(model, encoded_input)\n",
    "profession_name = {v: k for k, v in label_map.items()}[profession_index]  \n",
    "\n",
    "print(\"Predicted Profession:\", profession_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
